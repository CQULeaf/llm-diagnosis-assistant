{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed7c8a9d",
   "metadata": {},
   "source": [
    "# Ê®°ÂûãÂæÆË∞ÉÊµÅÁ®ã"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d175d986",
   "metadata": {},
   "source": [
    "## ÂØºÂÖ•Ê®°Âûã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8fca0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\23756\\miniconda3\\envs\\unsloth\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "from config import BASE_MODEL_PATH, NON_REASON_DATASET_PATH, REASON_DATASET_PATH, LORA_SAVE_PATH, MERGED_MODEL_PATH, COMBINED_DATASET_PATH\n",
    "#ÂàùÂßãÈáäÊîæÊòæÂ≠ò\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "775e7e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\23756\\miniconda3\\envs\\unsloth\\Lib\\site-packages\\unsloth_zoo\\gradient_checkpointing.py:341: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:28.)\n",
      "  GPU_BUFFERS = tuple([torch.empty(2*256*2048, dtype = dtype, device = f\"{DEVICE_TYPE}:{i}\") for i in range(n_gpus)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.6.5: Fast Qwen3 patching. Transformers: 4.52.4.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 3070 Ti Laptop GPU. Num GPUs = 1. Max memory: 8.0 GB. Platform: Windows.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.6. CUDA Toolkit: 12.6. Triton: 3.3.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:15<00:00,  5.29s/it]\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "max_seq_length = 8192\n",
    "dtype = None\n",
    "load_in_4bit = True\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = BASE_MODEL_PATH,\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3621a3",
   "metadata": {},
   "source": [
    "## ÂØºÂÖ•Êï∞ÊçÆÈõÜ\n",
    "Ê≠§Â§ÑÂ∫î‰∏∫Êï∞ÊçÆÈõÜÂ§ÑÁêÜËÑöÊú¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5a2c11",
   "metadata": {},
   "source": [
    "### Êó†ÊÄùËÄÉÊï∞ÊçÆÈõÜÂú®Ê≠§Â§Ñ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f70b7f9",
   "metadata": {},
   "source": [
    "### AIpacaHandler\n",
    "Ê≠§‰∏∫AIpacaÊ†ºÂºèÊï∞ÊçÆÈõÜÂ§ÑÁêÜÊñπÊ≥ï\n",
    "Ëá™Âä®ÂêàÂπ∂Â§ö‰∏™Êó†ÊÄùËÄÉÊï∞ÊçÆÈõÜ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44a7bae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÂÖ±Âä†ËΩΩÊó†ÊÄùËÄÉÂØπËØùÊï∞: 4337\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datasets import load_dataset\n",
    "from config import BASE_MODEL_PATH, NON_REASON_DATASET_PATH, REASON_DATASET_PATH, LORA_SAVE_PATH, MERGED_MODEL_PATH\n",
    "all_conversations = []\n",
    "for path in NON_REASON_DATASET_PATH:\n",
    "    ds = load_dataset(data_files=path, split=\"train\", path=\"json\")\n",
    "\n",
    "    for sample in ds:\n",
    "        user_msg = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": sample[\"instruction\"] + ((\"\\n\" + sample[\"input\"]) if sample.get(\"input\") else \"\")\n",
    "        }\n",
    "        assistant_msg = {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": sample[\"output\"]\n",
    "        }\n",
    "        all_conversations.append([user_msg, assistant_msg])\n",
    "\n",
    "non_reasoning_dataset = {\"conversations\": all_conversations}\n",
    "print(f\"ÂÖ±Âä†ËΩΩÊó†ÊÄùËÄÉÂØπËØùÊï∞: {len(non_reasoning_dataset['conversations'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b697aad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'ÂíΩÂñâÁóâÊåõÊòØ‰ªÄ‰πà'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'ÂíΩÂñâÁóâÊåõÊòØÂíΩÂñâÈÉ®ÁöÑËÇåËÇâÁóâÊåõÔºåÊ≠£Á°ÆÁöÑÂêçÁß∞Â∫îËØ•ÊòØÂíΩËÇåÁóâÊåõÂíåÂñâÁóâÊåõ„ÄÇÂíΩËÇåÁóâÊåõÂ∞±ÊòØËΩØËÖ≠ÂíåÂíΩËÇåÂèëÁîüËßÑÂæãÁöÑÊàñ‰∏çËßÑÂæãÁöÑÊî∂Áº©ËøêÂä®ÔºåÁîöËÄÖÊØèÂàÜÈíüÂèØËææ60ÔΩû100Ê¨°‰ª•‰∏äÔºå‰∏éËÑâÊêè„ÄÅÂëºÂê∏Êó†ÂÖ≥„ÄÇ\\n\\nÂçïÁ∫ØÁöÑÂíΩËÇåÁóâÊåõÔºåÂ§ßÂ§öÂéüÂõ†‰∏çÊòé„ÄÇÊÖ¢ÊÄßÂíΩÁÇéÁóÖ‰∫∫„ÄÅÁÉüÈÖíËøáÂ∫¶ËÄÖ„ÄÅÈºªÂàÜÊ≥åÁâ©ÈïøÊúüÂà∫ÊøÄÂíΩÈÉ®ÂèäÂ§ñÈÉ®Áâ©ÁêÜÂåñÂ≠¶Âõ†Á¥†ÁöÑÂΩ±ÂìçÂùáÊúâÂèØËÉΩÂØºËá¥ÂíΩËÇåÁóâÊåõÁöÑÂèëÁîü„ÄÇÂíΩËÇåÁöÑÈòµÂèëÊÄßÂº∫Áõ¥ÊÄßÁóâÊåõËæÉÂ∞ëËßÅÔºåÁôåËÇøÁöÑÁñºÁóõÂèØÂºïËµ∑ÔºåÁãÇÁä¨ÁóÖ„ÄÅÁ†¥‰º§È£éÂíåËÑëËÜúÁÇé‰ª•ÂèäÈ¢ÖÂÜÖÁñæÊÇ£ÁöÜÂèØËÉΩÂèëÁîüÂíΩËÇåÂº∫Áõ¥ÊÄßÈòµÊåõ„ÄÇÈòµÊåõÂèë‰ΩúÊó∂ÔºåÁóÖ‰∫∫ÂèäÊóÅ‰∫∫Â∏∏ÂèØÂê¨Âà∞ÊòéÊòæÁöÑËÇåËÇâÊî∂Áº©Â£∞„ÄÇÁóÖ‰∫∫Ëá™ËØâÂèØÂê¨ËßÅËá™Â∑±ÊúâËÄ≥È∏£Â£∞ÔºåÂç≥ÊâÄË∞ì‰ªñËßâÊÄßËÄ≥È∏£ÔºõËÄ≥È∏£Â£∞‰∏éËÑâÊêè‰∏ç‰∏ÄËá¥ÔºåÂéãËø´È¢àÂä®ËÑâÊó∂‰∏çÊ∂àÂ§±ÔºåÊïÖ‰∏∫ËÇåÊÄß‰ªñËßâÊÄßËÄ≥È∏£ÔºåÁóÖ‰∫∫Â∏∏ÊúâËá™Âê¨ËøáÊòæ‰πãÊÑüÔºåÂ∏∏ÊúâÂêûÂíΩÈöúÁ¢çÔºåÂíΩÂñâ‰∏çÈÄÇÔºåÂèçÂ§ç‰ΩúÂëïÂíåÂ±ÄÈÉ®ÁóõÊÑüÔºåÂ∏∏Âõ†Á≤æÁ•ûÊÅêÊÉßÂíåÁ¥ßÂº†ËÄåÂèë‰Ωú„ÄÇ\\n\\nÂñâÁóâÊåõÂàÜ‰∏∫Êàê‰∫∫ÂñâÁóâÊåõÔºåÂñâÊôïÂé•ÂíåËùâÈ∏£ÊÄßÂñâÁóâÊåõÔºàÂ∞èÂÑøÔºâ„ÄÇ'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_reasoning_dataset['conversations'][2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d56cdba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_reasoning_conversations = tokenizer.apply_chat_template(\n",
    "    non_reasoning_dataset[\"conversations\"],\n",
    "    tokenize = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf39a02",
   "metadata": {},
   "source": [
    "### ÊúâÊÄùËÄÉÊï∞ÊçÆÈõÜÂú®Ê≠§Â§Ñ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6529156f",
   "metadata": {},
   "source": [
    "### AIpacaHandler\n",
    "Ê≠§‰∏∫AIpacaÂ§ÑÁêÜÊñπÊ≥ïÔºàÊúâÊÄùËÄÉÊï∞ÊçÆÈõÜÔºâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bf30057",
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_dataset = load_dataset(data_files=REASON_DATASET_PATH, split = \"train\", path=\"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d22eae00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Please answer the following multiple-choice question:\\nA factory worker presents with excessive salivation, blue lines on gums, tremors, disturbed personality, insomnia, and loss of appetite. The most likely poisoning is -?\\nA. Mercury\\nB. Lead\\nC. Arsenic\\nD. Phosphorus',\n",
       " 'input': '',\n",
       " 'output': \"<think>\\nThe patient is a factory worker presenting with excessive salivation, blue lines on the gums, tremors, disturbed personality, insomnia, and loss of appetite. These symptoms collectively suggest a form of heavy metal poisoning. To determine the most likely poisoning, it is essential to meticulously analyze each symptom in the context of the provided options: Mercury, Lead, Arsenic, and Phosphorus.\\n\\nExcessive salivation, also known as ptyalism, is a significant symptom to consider. This symptom is notably associated with mercury poisoning, particularly with elemental mercury exposure, which can disrupt autonomic functions leading to increased salivation. Tremors, especially fine intention tremors, are another hallmark of mercury toxicity, reflecting its profound effects on the central nervous system. Disturbed personality and insomnia further support the neurological impact of mercury, aligning with the erethism syndrome‚Äîa classic presentation of chronic mercury poisoning characterized by behavioral changes, irritability, and insomnia. Loss of appetite is a non-specific symptom but can be present in various toxic exposures, including mercury.\\n\\nThe presence of blue lines on the gums, known as Burton's lines, is traditionally a classic indicator of lead poisoning. These lines result from the deposition of lead sulfide at the gum margins, providing a distinctive clinical sign. Additionally, lead poisoning often presents with peripheral neuropathy, which can manifest as weakness or, in some cases, tremors. However, lead toxicity is more commonly associated with symptoms such as abdominal pain, constipation, and anemia rather than excessive salivation and significant personality changes.\\n\\nArsenic poisoning typically presents with acute gastrointestinal distress, including nausea, vomiting, diarrhea, and abdominal pain. Chronic exposure may lead to skin changes, such as hyperpigmentation and keratosis, as well as an increased risk of various cancers. While neurological symptoms can occur, they are generally not as prominent as in mercury or lead poisoning. The absence of characteristic skin lesions and the prominence of neurological symptoms make arsenic a less likely culprit in this scenario.\\n\\nPhosphorus poisoning, particularly from white phosphorus, can cause severe gastrointestinal symptoms similar to arsenic and may be associated with a garlic-like odor on the breath or vomit. Chronic exposure can lead to liver and kidney damage, but it is not typically associated with the neurological symptoms or the blue lines on the gums described in this patient.\\n\\nIn evaluating the options, Mercury emerges as the most plausible cause despite the presence of blue lines on the gums, which are more classically associated with lead poisoning. The constellation of excessive salivation, tremors, disturbed personality, insomnia, and loss of appetite aligns more closely with mercury toxicity. While Burton's lines are a strong indicator of lead exposure, the additional neurological symptoms presented by the patient‚Äîparticularly excessive salivation and erethism‚Äîare more characteristic of mercury poisoning. It is possible that the blue lines in this case are either a less common manifestation of mercury toxicity or a coincidental finding not directly related to the acute presentation.\\n\\nContrasting Mercury and Lead poisoning, both can present with neurological symptoms such as tremors and cognitive disturbances. However, the specific combination of excessive salivation and erethism strongly favors mercury as the causative agent. Lead poisoning's hallmark Burton's lines, while present, are insufficient alone to outweigh the broader spectrum of neurological symptoms pointing towards mercury. Additionally, the absence of more pronounced gastrointestinal symptoms such as constipation and abdominal pain, which are more typical of lead toxicity, further diminishes the likelihood of lead poisoning in this context.\\n\\nIn synthesizing the information, the convergence of symptoms‚Äîexcessive salivation, tremors, disturbed personality, insomnia, and loss of appetite‚Äîcollectively points towards mercury poisoning as the most likely diagnosis. The presence of blue lines on the gums, although suggestive of lead poisoning, does not overshadow the predominant neurological manifestations consistent with mercury toxicity. Therefore, taking into account the entirety of the clinical presentation, mercury remains the most plausible cause among the provided options.\\n\\nThe correct answer is Mercury.\\n\\nClinicians should be aware that while certain symptoms like Burton's lines are strongly associated with specific poisonings, the overall clinical picture must guide the diagnosis. Excessive salivation and erethism are key indicators of mercury toxicity, and their presence should prompt consideration of mercury exposure even if other signs might initially suggest a different heavy metal poisoning. Recognizing the nuanced presentations of heavy metal toxicities is crucial for accurate diagnosis and timely management.\\n</think>\\nThe patient, a factory worker, exhibits symptoms including excessive salivation, blue lines on the gums, tremors, disturbed personality, insomnia, and loss of appetite, indicating potential heavy metal poisoning. Analyzing the symptoms in relation to possible toxins‚ÄîMercury, Lead, Arsenic, and Phosphorus‚Äîsuggests mercury poisoning as the most likely cause. \\n\\nExcessive salivation and tremors are closely associated with mercury toxicity, particularly affecting the central nervous system, leading to behavioral changes and insomnia. Although blue lines on the gums are indicative of lead poisoning, the overall neurological symptoms and lack of typical lead symptoms (like abdominal pain and constipation) support mercury as the primary diagnosis. Arsenic and phosphorus poisoning present with different symptom profiles that do not align with this case.\\n\\nIn conclusion, despite the presence of Burton's lines, the predominant symptoms of excessive salivation, tremors, and personality changes point towards mercury poisoning as the most plausible diagnosis. Clinicians should consider the full clinical picture when diagnosing heavy metal poisoning, as certain symptoms may overlap between different toxins.\"}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reasoning_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9e46161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'> 3000\n",
      "[{'role': 'user', 'content': \"Please answer the following multiple-choice question:\\nRett's syndrome occurs due to deficiency of ?\\nA. Niacin\\nB. Biotin\\nC. Carotene\\nD. Vit D\"}, {'role': 'assistant', 'content': \"<think>\\nRett's syndrome is a severe neurodevelopmental disorder that predominantly affects females and is characterized by a regression in cognitive and motor skills after a period of apparently normal development. It typically manifests in early childhood, with symptoms becoming noticeable between the ages of 6 to 18 months. The condition involves a range of neurological symptoms, including loss of purposeful hand movements, slowed growth, seizures, and difficulties with communication and social interaction. Importantly, Rett's syndrome is a genetic disorder caused by mutations in the MECP2 gene, which is located on the X chromosome. This gene plays a critical role in brain development and function by regulating the expression of other genes essential for neuronal function.\\n\\nIn analyzing the question, it's essential to recognize that Rett's syndrome is fundamentally a genetic disorder rather than a condition resulting from a deficiency of a specific nutrient or vitamin. The provided options‚ÄîNiacin, Biotin, Carotene, and Vitamin D‚Äîare all vitamins, each with distinct roles in bodily functions. Niacin (vitamin B3) is crucial for energy metabolism and DNA repair, Biotin (vitamin B7) is important for carbohydrate, fat, and protein metabolism, Carotene is a precursor to vitamin A and is vital for vision and immune function, and Vitamin D is essential for calcium homeostasis and bone health. None of these vitamins are directly implicated in the pathogenesis of Rett's syndrome.\\n\\nReviewing the original chain-of-thought, there was a misinterpretation of the disease's etiology by focusing on vitamin deficiencies. Rett's syndrome's cause is not linked to nutritional deficiencies but rather to a specific genetic mutation. The MECP2 gene mutation disrupts normal brain development and function, leading to the clinical manifestations observed in Rett's syndrome. This genetic basis is well-documented in medical literature and is a cornerstone in understanding the disease's pathophysiology.\\n\\nOption-by-option analysis reveals the following:\\n\\n1. **Niacin**: Deficiency in Niacin leads to pellagra, which is characterized by dermatitis, diarrhea, and dementia. While neurological symptoms can occur, pellagra is unrelated to Rett's syndrome, which has a distinct genetic origin.\\n\\n2. **Biotin**: Biotin deficiency can cause neurological symptoms such as seizures, skin rashes, and hair loss. However, like Niacin, Biotin deficiency does not cause Rett's syndrome. The confusion may arise because both conditions involve neurological symptoms, but their etiologies are entirely different.\\n\\n3. **Carotene**: As a precursor to vitamin A, Carotene deficiency results in issues like night blindness and compromised immune function. There is no association between Carotene levels and Rett's syndrome.\\n\\n4. **Vitamin D**: Deficiency in Vitamin D leads to bone disorders such as rickets in children or osteomalacia in adults. It does not influence the neurological aspects seen in Rett's syndrome.\\n\\nGiven that Rett's syndrome is exclusively linked to genetic mutations, none of the provided options are accurate causes of the condition. However, in a multiple-choice scenario where an answer must be selected despite none being correct, **Biotin** might be chosen due to its association with neurological functions. This selection, though, would be technically incorrect, as Biotin deficiency does not cause Rett's syndrome. The error in the original attempt stemmed from conflating general neurological deficiencies with the specific genetic cause of Rett's syndrome.\\n\\nComparing Biotin to the other options, it's evident that while Biotin has neurological implications, so do the other vitamins, none specifically relate to Rett's syndrome's genetic basis. Therefore, differentiating between general nutrient deficiencies and specific genetic disorders is crucial in such clinical questions. The provided error feedback correctly identifies that the original reasoning erroneously links Rett's syndrome to a vitamin deficiency rather than its true genetic origin.\\n\\nIn conclusion, the accurate understanding is that Rett's syndrome is caused by mutations in the MECP2 gene, and none of the vitamin deficiencies listed‚ÄîNiacin, Biotin, Carotene, or Vitamin D‚Äîare responsible for its development. Therefore, the correct answer is not among the provided options. However, if compelled to choose from the given list, Biotin would be the closest albeit incorrect option due to its neurological role, but it's essential to acknowledge that this selection does not reflect the actual cause of Rett's syndrome.\\n\\nA key clinical pearl is to always consider the fundamental nature of a disorder‚Äîdistinguishing between genetic causes and nutritional deficiencies is vital for accurate diagnosis and management. Understanding the underlying mechanisms, such as the role of the MECP2 gene in Rett's syndrome, helps in differentiating it from other conditions with overlapping symptoms but different etiologies. This approach ensures precise clinical reasoning and appropriate patient care.\\n</think>\\nRett's syndrome is a severe neurodevelopmental disorder primarily affecting females, characterized by a regression in cognitive and motor skills after a period of normal development, typically noticeable between 6 to 18 months of age. It is caused by mutations in the MECP2 gene on the X chromosome, which is crucial for brain development and function. The condition presents with various neurological symptoms, including loss of purposeful hand movements, slowed growth, seizures, and communication difficulties.\\n\\nThe analysis clarifies that Rett's syndrome is a genetic disorder, not linked to deficiencies in vitamins such as Niacin, Biotin, Carotene, or Vitamin D. Each vitamin has distinct roles in the body, but none are implicated in the etiology of Rett's syndrome. The reasoning initially misinterpreted the condition's cause by associating it with vitamin deficiencies rather than recognizing its genetic basis.\\n\\nWhile Biotin has some neurological implications, it does not cause Rett's syndrome. The key takeaway is to differentiate between genetic disorders and nutritional deficiencies, which is essential for accurate diagnosis and management. Understanding the MECP2 gene's role is crucial in distinguishing Rett's syndrome from other conditions with similar symptoms but different causes. Thus, none of the listed vitamins are responsible for Rett's syndrome, and if forced to choose, Biotin would be the closest incorrect option due to its neurological relevance.\"}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "dataset = {\"conversations\": []}\n",
    "\n",
    "for sample in reasoning_dataset:\n",
    "    user_msg = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": sample[\"instruction\"] + ((\"\\n\" + sample[\"input\"]) if sample.get(\"input\") else \"\")\n",
    "    }\n",
    "    assistant_msg = {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": sample[\"output\"]\n",
    "    }\n",
    "    dataset[\"conversations\"].append([user_msg, assistant_msg])\n",
    "\n",
    "print(type(dataset), len(dataset[\"conversations\"]))\n",
    "print(dataset[\"conversations\"][1])\n",
    "reasoning_dataset = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9650bfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "reasoning_conversations = tokenizer.apply_chat_template(\n",
    "    reasoning_dataset[\"conversations\"],\n",
    "    tokenize = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b52ac8a",
   "metadata": {},
   "source": [
    "### Êï∞ÊçÆÈõÜÂêàÂπ∂\n",
    "ÊúâÊÄùËÄÉÊï∞ÊçÆ‰∏∫reasoning_dataset  \n",
    "Êó†ÊÄùËÄÉÊï∞ÊçÆ‰∏∫non_reasoning_dataset  \n",
    "Áé∞Â∞Ü‰∫åËÄÖÂêàÂπ∂‰∏∫combined_dataset  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49259c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "4337\n"
     ]
    }
   ],
   "source": [
    "print(len(reasoning_conversations))\n",
    "print(len(non_reasoning_conversations))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea378be1",
   "metadata": {},
   "source": [
    "Ê†πÊçÆÊúâÊÄùËÄÉÂíåÊó†ÊÄùËÄÉÊï∞ÊçÆÊØî‰æãÂêàÂπ∂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f23c14a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ËøôÈáåÂ∞±ÊòØË∞ÉÊï¥ÊØî‰æã\n",
    "chat_percentage = 0.75\n",
    "import pandas as pd\n",
    "reasoning_subset = pd.Series(reasoning_conversations)\n",
    "# reasoning_subset = reasoning_subset.sample(\n",
    "#     int(len(non_reasoning_conversations) / (1.0 - chat_percentage)),\n",
    "#     random_state = 2407,\n",
    "# )\n",
    "\n",
    "data = pd.concat([\n",
    "    pd.Series(non_reasoning_conversations),\n",
    "    pd.Series(reasoning_subset)\n",
    "])\n",
    "data.name = \"text\"\n",
    "\n",
    "from datasets import Dataset\n",
    "combined_dataset = Dataset.from_pandas(pd.DataFrame(data))\n",
    "combined_dataset = combined_dataset.shuffle(seed = 3407)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd1df5fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7337"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dfd61dc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', '__index_level_0__'],\n",
       "    num_rows: 7337\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788bc163",
   "metadata": {},
   "source": [
    "ÂèØ‰ª•Â∞ÜÂêàÂπ∂ÂêéÁöÑÊï∞ÊçÆÈõÜÂØºÂá∫Ôºå‰∏ãÊ¨°Áõ¥Êé•Áî®Ê≠§ÂØºÂÖ•ÂêéËÆ≠ÁªÉ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866b164d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:01<00:00,  5.54ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "37263409"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_dataset.to_json(COMBINED_DATASET_PATH, force_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8abefb8",
   "metadata": {},
   "source": [
    "Áõ¥Êé•ÂØºÂÖ•ÂÆåÂÖ®Â§ÑÁêÜÂ•ΩÁöÑÊï∞ÊçÆÈõÜ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6853ca78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.arrow_dataset.Dataset'>\n",
      "7337\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': '<|im_start|>user\\nÁΩóÊ†ºÂàóÈÖÆÁâáÁöÑÊâßË°åÊ†áÂáÜ<|im_end|>\\n<|im_start|>assistant\\n<think>\\n\\n</think>\\n\\nÂõΩÂÆ∂È£üÂìÅËçØÂìÅÁõëÁù£ÁÆ°ÁêÜÂ±ÄÂõΩÂÆ∂ËçØÂìÅÊ†áÂáÜWS1-XG-019-2014„ÄÇ<|im_end|>\\n',\n",
       " '__index_level_0__': 3177}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Áõ¥Êé•Áî®load_datasetÂä†ËΩΩjsonÊñá‰ª∂ÔºåÂæóÂà∞ÁöÑÂ∞±ÊòØDatasetÂØπË±°\n",
    "combined_dataset = load_dataset(\"json\", data_files=COMBINED_DATASET_PATH, split=\"train\")\n",
    "print(type(combined_dataset))\n",
    "print(len(combined_dataset))\n",
    "combined_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2a97a1",
   "metadata": {},
   "source": [
    "## Ê®°ÂûãËÆ≠ÁªÉ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "066491f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.6.5 patched 36 layers with 36 QKV layers, 36 O layers and 36 MLP layers.\n",
      "average_tokens_across_devices is set to True but it is invalid when world size is1. Turn it to False automatically.\n",
      "Unsloth: Tokenizing [\"text\"]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7337/7337 [00:04<00:00, 1515.58 examples/s]\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 32,           # Choose any number > 0! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 32,  # Best to choose alpha = rank or rank*2\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,   # We support rank stabilized LoRA\n",
    "    loftq_config = None,  # And LoftQ\n",
    ")\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = combined_dataset,\n",
    "    eval_dataset = None, # Can set up evaluation!\n",
    "    args = SFTConfig(\n",
    "        dataset_num_proc = 1,\n",
    "        dataset_text_field = \"text\",\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4, # Use GA to mimic batch size!\n",
    "        warmup_steps = 5,\n",
    "        # num_train_epochs = 1, # Set this for 1 full training run.\n",
    "        max_steps = 30,\n",
    "        learning_rate = 2e-4, # Reduce to 2e-5 for long training runs\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        report_to = None, # Use this for WandB etc\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e708bbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 7,337 | Num Epochs = 1 | Total steps = 30\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 66,060,288/4,000,000,000 (1.65% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 10:11, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.526800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.584100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.583900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.363100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.228800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.184400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.063300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.208700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.162000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.153900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.034500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.062300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.121300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.308100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.079300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.119900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.984200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.033500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.993200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.038500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.965900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.988800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.150100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.986800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.051300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.955300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.088700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.912300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e56cca2",
   "metadata": {},
   "source": [
    "## Ê®°Âûã‰øùÂ≠ò\n",
    "Ê≥®ÊÑè‰øÆÊîπË∑ØÂæÑÔºå‰øùÂ≠ò‰∏∫Á¨¶ÂêàHFËßÑËåÉÁöÑÊñá‰ª∂Â§π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "061c3784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C:/Users/23756/demo/Qwen3-4b-v0.3\\\\tokenizer_config.json',\n",
       " 'C:/Users/23756/demo/Qwen3-4b-v0.3\\\\special_tokens_map.json',\n",
       " 'C:/Users/23756/demo/Qwen3-4b-v0.3\\\\chat_template.jinja',\n",
       " 'C:/Users/23756/demo/Qwen3-4b-v0.3\\\\vocab.json',\n",
       " 'C:/Users/23756/demo/Qwen3-4b-v0.3\\\\merges.txt',\n",
       " 'C:/Users/23756/demo/Qwen3-4b-v0.3\\\\added_tokens.json',\n",
       " 'C:/Users/23756/demo/Qwen3-4b-v0.3\\\\tokenizer.json')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ‰øùÂ≠ò LoRA adapter ÊùÉÈáç\n",
    "model.save_pretrained(LORA_SAVE_PATH)\n",
    "\n",
    "# ‰øùÂ≠ò tokenizerÔºàÂèØ‰ª•Ë∑≥ËøáÔºåÂ¶ÇÊûúÊ≤°ÊúâÊîπÂä®ËøáÔºâ\n",
    "tokenizer.save_pretrained(LORA_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1bd1f278",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:12<00:00,  4.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LoRA adapter...\n",
      "Merging LoRA weights into the base model...\n",
      "Saving merged model to C:/Users/23756/demo/merged-Qwen3-4b-v0.3 ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('C:/Users/23756/demo/merged-Qwen3-4b-v0.3\\\\tokenizer_config.json',\n",
       " 'C:/Users/23756/demo/merged-Qwen3-4b-v0.3\\\\special_tokens_map.json',\n",
       " 'C:/Users/23756/demo/merged-Qwen3-4b-v0.3\\\\chat_template.jinja',\n",
       " 'C:/Users/23756/demo/merged-Qwen3-4b-v0.3\\\\vocab.json',\n",
       " 'C:/Users/23756/demo/merged-Qwen3-4b-v0.3\\\\merges.txt',\n",
       " 'C:/Users/23756/demo/merged-Qwen3-4b-v0.3\\\\added_tokens.json',\n",
       " 'C:/Users/23756/demo/merged-Qwen3-4b-v0.3\\\\tokenizer.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import PeftModel\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "\n",
    "base_model_path = BASE_MODEL_PATH\n",
    "lora_model_path = LORA_SAVE_PATH  # ‰Ω†ËÆ≠ÁªÉÂêé‰øùÂ≠òÁöÑË∑ØÂæÑ\n",
    "merged_model_path = MERGED_MODEL_PATH  # ÂêàÂπ∂Âêé‰øùÂ≠òË∑ØÂæÑ\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_path,\n",
    "    torch_dtype=torch.float16,       # Ê†πÊçÆÂÆûÈôÖÊòæÂ≠òÂèØÈÄâ float16/float32\n",
    "    low_cpu_mem_usage=True\n",
    ").to(device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_path)\n",
    "\n",
    "# 2. ‰ªé LoRA adapter Âä†ËΩΩÂ¢ûÈáèÊùÉÈáç\n",
    "print(\"Loading LoRA adapter...\")\n",
    "peft_model = PeftModel.from_pretrained(\n",
    "    base_model,\n",
    "    lora_model_path,\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# 3. ÂêàÂπ∂ LoRA Âà∞Âü∫Á°ÄÊ®°Âûã\n",
    "print(\"Merging LoRA weights into the base model...\")\n",
    "merged_model = peft_model.merge_and_unload()\n",
    "\n",
    "# 4. ‰øùÂ≠òÂêàÂπ∂ÂêéÁöÑÊ®°ÂûãÂíåÂàÜËØçÂô®\n",
    "print(f\"Saving merged model to {merged_model_path} ...\")\n",
    "merged_model.save_pretrained(merged_model_path)\n",
    "tokenizer.save_pretrained(merged_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85200630",
   "metadata": {},
   "source": [
    "## Ê®°ÂûãÈáèÂåñ\n",
    "Â∞ÜHFÊ†ºÂºèÁöÑÊ®°ÂûãËΩ¨Êç¢‰∏∫GGUFÊ†ºÂºèÁöÑÊ®°ÂûãÔºå‰æø‰∫évllmÊàñollamaÈÉ®ÁΩ≤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cd592e",
   "metadata": {},
   "source": [
    "ÊâßË°åÂëΩ‰ª§Â∞ÜÂêàÂπ∂ÂêéHFÊ®°ÂûãËΩ¨Êç¢‰∏∫binÊñá‰ª∂  \n",
    "cd llama.cpp  \n",
    "python convert_hf_to_gguf.py ‰Ω†ÁöÑÂêàÂπ∂Ê®°ÂûãË∑ØÂæÑ --outtype f16 --outfile binÊñá‰ª∂Ë∑ØÂæÑ  \n",
    "  \n",
    "ÂÜçÂ∞ÜbinÊñá‰ª∂ÈáèÂåñ‰∏∫ggufÊñá‰ª∂(ÂèÇÊï∞Ëá™ÈÄâ)  \n",
    "f16Áõ∏ÂΩì‰∫éÊ≤°ÈáèÂåñÔºåÂ¶ÇÊûúÂêéÁª≠Âü∫Ê®°ÂûãÁî®Êú™ÈáèÂåñÁöÑÂàôÂèØÂú®ÊúçÂä°Âô®ÂæÆË∞ÉÂêéÈÄâÂàôq4_kÁ≠âÈáèÂåñÂêéÂú®‰∏ªÊú∫ÈÉ®ÁΩ≤  \n",
    "llama-quantize ËæìÂÖ•binÊñá‰ª∂ ËæìÂá∫ggufÊñá‰ª∂ ÈáèÂåñÁ±ªÂûã  \n",
    "  \n",
    "Âú®Ê†πÁõÆÂΩï‰∏ãËæìÂÖ•‰ª•‰∏ãÊåá‰ª§‰ª•Â∞Ü‰Ω†ÁöÑÊ®°ÂûãÂØºÂÖ•ollama‰∏≠  \n",
    "ollama create ‰Ω†ÁöÑÊ®°ÂûãÂêçÁß∞"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960ef0ed",
   "metadata": {},
   "source": [
    "## ÂØπHFÊ†ºÂºèÁöÑÊ®°ÂûãËøõË°åÁÆÄÂçïÊµãËØï"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4ffe0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'mymodel_v0.3:latest', 'created_at': '2025-06-28T15:11:12.2114899Z', 'response': '<think>\\n\\n</think>\\n\\nÊàëÁêÜËß£ÊÇ®ÂØπÊàëÁöÑËÉΩÂäõÊÑüÂÖ¥Ë∂£„ÄÇ‰Ωú‰∏∫‰∏ÄÊ¨æÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºåÊàëÂèØ‰ª•ËøõË°åÊ∑±Â∫¶Êé®ÁêÜÂíåÂ§çÊùÇÁöÑÈÄªËæëÂàÜÊûêÔºå‰ΩÜÊàë‰∏çÂÖ∑Â§áËá™‰∏ªÁöÑÊÑèËØÜÊàñÊÉÖÊÑü„ÄÇÊàëÁöÑÂäüËÉΩ‰∏ªË¶ÅÂü∫‰∫éÁÆóÊ≥ïÂíåÊï∞ÊçÆÂàÜÊûêÔºåËÉΩÂ§üÁêÜËß£ÂíåÁîüÊàêËá™ÁÑ∂ËØ≠Ë®ÄÊñáÊú¨„ÄÅÂõûÁ≠îÈóÆÈ¢ò„ÄÅÂàõ‰ΩúÂÜÖÂÆπÁ≠â„ÄÇ\\n\\nÂ¶ÇÊûúÊÇ®Êúâ‰ªª‰ΩïÂÖ∑‰ΩìÁöÑÈóÆÈ¢òÊàñÈúÄË¶ÅÂ∏ÆÂä©ÁöÑÂú∞ÊñπÔºåËØ∑ÈöèÊó∂ÂëäËØâÊàëÔºÅ', 'done': True, 'done_reason': 'stop', 'context': [151644, 8948, 319, 56568, 101909, 15469, 110498, 151645, 319, 151644, 872, 319, 108386, 3837, 56568, 18830, 102141, 63314, 101037, 151645, 319, 151644, 77091, 319, 151667, 271, 151668, 271, 35946, 101128, 87026, 32664, 97611, 99788, 103198, 1773, 100622, 104794, 101951, 102064, 104949, 3837, 109944, 71817, 102217, 113272, 33108, 106888, 104913, 101042, 3837, 77288, 101553, 102094, 100842, 9370, 100708, 57191, 104934, 1773, 97611, 98380, 99558, 104210, 107018, 33108, 111540, 3837, 100006, 115167, 43959, 99795, 102064, 108704, 5373, 102104, 86119, 5373, 104223, 43815, 49567, 3407, 106870, 110117, 100398, 103936, 57191, 85106, 100364, 103958, 37945, 102422, 106525, 6313], 'total_duration': 6386414100, 'load_duration': 55234300, 'prompt_eval_count': 24, 'prompt_eval_duration': 257509200, 'eval_count': 71, 'eval_duration': 6073164600}\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "ÊàëÁêÜËß£ÊÇ®ÂØπÊàëÁöÑËÉΩÂäõÊÑüÂÖ¥Ë∂£„ÄÇ‰Ωú‰∏∫‰∏ÄÊ¨æÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºåÊàëÂèØ‰ª•ËøõË°åÊ∑±Â∫¶Êé®ÁêÜÂíåÂ§çÊùÇÁöÑÈÄªËæëÂàÜÊûêÔºå‰ΩÜÊàë‰∏çÂÖ∑Â§áËá™‰∏ªÁöÑÊÑèËØÜÊàñÊÉÖÊÑü„ÄÇÊàëÁöÑÂäüËÉΩ‰∏ªË¶ÅÂü∫‰∫éÁÆóÊ≥ïÂíåÊï∞ÊçÆÂàÜÊûêÔºåËÉΩÂ§üÁêÜËß£ÂíåÁîüÊàêËá™ÁÑ∂ËØ≠Ë®ÄÊñáÊú¨„ÄÅÂõûÁ≠îÈóÆÈ¢ò„ÄÅÂàõ‰ΩúÂÜÖÂÆπÁ≠â„ÄÇ\n",
      "\n",
      "Â¶ÇÊûúÊÇ®Êúâ‰ªª‰ΩïÂÖ∑‰ΩìÁöÑÈóÆÈ¢òÊàñÈúÄË¶ÅÂ∏ÆÂä©ÁöÑÂú∞ÊñπÔºåËØ∑ÈöèÊó∂ÂëäËØâÊàëÔºÅ\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "url = \"http://localhost:11434/api/generate\"\n",
    "system_prompt = (\n",
    "    \"‰Ω†ÊòØ‰∏Ä‰∏™AIÂä©Êâã\"\n",
    ")\n",
    "user_input = (\n",
    "    \"‰Ω†Â•ΩÔºå‰Ω†ÊúâÊÄùÁª¥ÈìæÂêó\"\n",
    ")\n",
    "payload = {\n",
    "    \"model\": \"mymodel_v0.3:latest\",  # ÊàñËÄÖ‰Ω†Âú® Ollama ‰∏≠ÂØºÂÖ•Êó∂ËÆæÁΩÆÁöÑÊ®°ÂûãÂêç\n",
    "    \"system\": system_prompt,\n",
    "    \"prompt\": user_input,\n",
    "    \"stream\": False,\n",
    "    \"thinking\": True,  # Â¶ÇÊûú‰∏çÈúÄË¶ÅÊÄùËÄÉËøáÁ®ãÔºåÂèØ‰ª•ËÆæÁΩÆ‰∏∫ False\n",
    "}\n",
    "# ÂèëÈÄÅËØ∑Ê±Ç\n",
    "response = requests.post(url, json=payload)\n",
    "print(response.json())\n",
    "text = response.json()[\"response\"]\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
